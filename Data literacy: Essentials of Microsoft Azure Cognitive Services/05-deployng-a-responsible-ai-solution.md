# Pubblicare una responsabile soluzione AI

In linea di principio generale sarebbe meglio che un progetto IT sia il più efficiente, sostenibile ed economico possibile.

## principi per una responsabile soluzione AI

1. **Equità**, i sistemi AI dovrebbero trattare le persone equamente, per esempio immaginate di creare un software AI per supportare l'approvamento di prestiti bancari. L'AI deve basare le sue **decisioni senza BIAS** su genere, etnia o altri fattori che porterebbero vantaggi o svantaggi tra persone.

> Azure Machine Learning include la possibilità di interpretare modelli e quantificare la misura in cui ogni feature dei dati influenzi la predizione del modello. Questo aiuta data scientist e sviluppatori ad identificare e mitigare i bias nel modello

2. **Affidabilità**, per esempio un sistema AI per un veicolo autonomo o che diagnostica malattie. Una mancanza di affidabilità in questi casi d'uso porta rischi di vita. Per questo servono test rigorosi e vari processi per assicurare che le AI lavorino come ci si aspetterebbe prima della release.
3. **privacy e sicurezza**, un sistema AI dovrebbe essere sicuro e rispettare la privacy. I sistemi su cui si basano le AI sono basati su quantità molto grosse di dati, tra questi potrebbero esserci dei dati personali che devono restare privati. Questo può valere anche per un sistema in produzione.
4. **Inclusività**, i sistemi AI dovrebbero dare potere a tutti e coinvolgere le persone, l'AI dovrebbe portare benefici a tutte le parti della società.
5. **Transparenza**, i sistemi AI dovrebbero essere spiegabili o capibili, gli utenti dovrebbero essere completamente informati dello scopo del sistema, come funzioni e quali limitazioni può avere
6. **Responsabilità**, L'AI deve seguire comportamenti etici e legali
